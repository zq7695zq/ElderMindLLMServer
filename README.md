# ElderMind LLM Server

åŸºäºSpringAIå’Œæ™ºè°±AIå®ç°çš„è§†é¢‘è¡Œä¸ºåˆ†æLLMæ¨ç†æœåŠ¡ï¼Œç”¨äºè€å¹´äººè¡Œä¸ºç›‘æŠ¤ç³»ç»Ÿã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ¥ **è§†é¢‘æ¨ç†**: æ”¯æŒé€šè¿‡URLç›´æ¥è®¿é—®è§†é¢‘ç‰‡æ®µè¿›è¡Œæ™ºè°±AIæ¨ç†åˆ†æ
- ğŸŒ **URLæ”¯æŒ**: ç›´æ¥æ¥æ”¶è§†é¢‘URLï¼Œæ— éœ€æœ¬åœ°æ–‡ä»¶ä¸Šä¼ 
- ğŸš¦ **é™æµæ§åˆ¶**: æ™ºèƒ½çš„å¹¶å‘å’Œé¢‘ç‡é™åˆ¶
- ğŸ”„ **é‡è¯•æœºåˆ¶**: è‡ªåŠ¨é‡è¯•å¤±è´¥çš„æ¨ç†è¯·æ±‚
- ğŸ“Š **ç»“æœä¿å­˜**: è‡ªåŠ¨ä¿å­˜æ¨ç†ç»“æœåˆ°æœ¬åœ°æ–‡ä»¶
- ğŸ”§ **é…ç½®çµæ´»**: ä¸°å¯Œçš„é…ç½®é€‰é¡¹
- ğŸ“ˆ **çŠ¶æ€ç›‘æ§**: å®æ—¶æœåŠ¡çŠ¶æ€æŸ¥è¯¢

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

- Java 21+
- Maven 3.6+
- æ™ºè°±AI API Key

### 2. é…ç½®

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨ .env æ–‡ä»¶ï¼ˆæ¨èï¼‰

1. å¤åˆ¶ `.env.example` æ–‡ä»¶ä¸º `.env`ï¼š
```bash
cp .env.example .env
```

2. ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„æ™ºè°±AI API Keyï¼š
```env
ZHIPUAI_API_KEY=your-zhipu-api-key-here
```

#### æ–¹å¼äºŒï¼šç¯å¢ƒå˜é‡

```bash
export ZHIPUAI_API_KEY=your-zhipu-api-key-here
```

#### æ–¹å¼ä¸‰ï¼šç›´æ¥ä¿®æ”¹é…ç½®æ–‡ä»¶

åœ¨ `application.yml` ä¸­é…ç½®æ™ºè°±AI API Keyï¼š

```yaml
spring:
  ai:
    zhipuai:
      api-key: your-zhipu-api-key-here
```

> **æ³¨æ„**: ä¸ºäº†å®‰å…¨èµ·è§ï¼Œå»ºè®®ä½¿ç”¨ `.env` æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡çš„æ–¹å¼é…ç½®API Keyï¼Œé¿å…å°†æ•æ„Ÿä¿¡æ¯æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿã€‚

### 3. å¯åŠ¨æœåŠ¡

```bash
mvn spring-boot:run
```

æœåŠ¡å°†åœ¨ `http://localhost:8080` å¯åŠ¨ã€‚

## API æ¥å£

### è§†é¢‘æ¨ç†æ¥å£

**POST** `/api/llm/inference`

è¯·æ±‚ä½“ï¼š
```json
{
  "videoUrl": "https://example.com/video.mp4",
  "customPrompt": "è¯·åˆ†æè§†é¢‘ä¸­çš„è¡Œä¸ºæ˜¯å¦å­˜åœ¨è·Œå€’é£é™©"
}
```

å“åº”ï¼š
```json
{
  "success": true,
  "result": {
    "action_analysis": {
      "detected_action": "æ­£å¸¸è¡Œèµ°",
      "confidence_score": 0.95,
      "action_category": "æ—¥å¸¸æ´»åŠ¨",
      "risk_level": "ä½",
      "description": "è€äººæ­£å¸¸è¡Œèµ°ï¼Œæ­¥æ€ç¨³å®š"
    },
    "context_analysis": {
      "environment": "å®¤å†…å®¢å…",
      "person_state": "è¡Œèµ°çŠ¶æ€è‰¯å¥½",
      "objects_involved": ["æ²™å‘", "èŒ¶å‡ "],
      "time_duration": "çº¦5ç§’"
    },
    "recommendations": {
      "immediate_action": "å¦",
      "monitoring_level": "å¸¸è§„",
      "alert_type": "æ— ",
      "suggestions": ["ç»§ç»­æ­£å¸¸ç›‘æ§"]
    }
  },
  "rawResponse": "...",
  "inferenceTime": 2.5,
  "videoPath": "https://example.com/video.mp4",
  "timestamp": "2024-01-20T10:30:00",
  "mode": "api"
}
```

### æœåŠ¡çŠ¶æ€æ¥å£

**GET** `/api/llm/status`

å“åº”ï¼š
```json
{
  "enabled": true,
  "mode": "api",
  "rateLimiter": {
    "enabled": true,
    "concurrent": {
      "current": 1,
      "max": 3,
      "available": 2
    },
    "rateLimits": {
      "perMinute": {
        "current": 5,
        "max": 30,
        "remaining": 25
      },
      "perHour": {
        "current": 45,
        "max": 500,
        "remaining": 455
      }
    }
  }
}
```

### å¥åº·æ£€æŸ¥æ¥å£

**GET** `/api/llm/health`

å“åº”ï¼š
```json
{
  "status": "UP",
  "service": "LLM Inference Service",
  "timestamp": 1705737000000
}
```

## é…ç½®è¯´æ˜

### æ ¸å¿ƒé…ç½®

```yaml
llm:
  inference:
    enabled: true          # æ˜¯å¦å¯ç”¨LLMæ¨ç†
    mode: api              # æ¨ç†æ¨¡å¼ï¼šapi
    model: glm-4v-plus     # æ™ºè°±AIæ¨¡å‹åç§°
    timeout: 60            # æ¨ç†è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    max-retries: 3         # æœ€å¤§é‡è¯•æ¬¡æ•°
```

### é™æµé…ç½®

```yaml
llm:
  inference:
    rate-limiter:
      enabled: true                    # æ˜¯å¦å¯ç”¨é™æµ
      max-concurrent-requests: 3       # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
      max-requests-per-minute: 30      # æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°
      max-requests-per-hour: 500       # æ¯å°æ—¶æœ€å¤§è¯·æ±‚æ•°
      queue-timeout: 30                # é˜Ÿåˆ—ç­‰å¾…è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
      retry-delay: 1.0                 # é‡è¯•å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
```

### æç¤ºè¯é…ç½®

```yaml
llm:
  inference:
    prompt-config:
      system-prompt: |
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘è¡Œä¸ºåˆ†æä¸“å®¶...
      user-prompt: "è¯·ä»”ç»†åˆ†æè¿™ä¸ªè§†é¢‘ä¸­çš„äººä½“åŠ¨ä½œè¡Œä¸º"
```

## ä½¿ç”¨ç¤ºä¾‹

### cURL ç¤ºä¾‹

```bash
# è§†é¢‘æ¨ç†
curl -X POST http://localhost:8080/api/llm/inference \
  -H "Content-Type: application/json" \
  -d '{
    "videoUrl": "https://example.com/video.mp4",
    "customPrompt": "åˆ†æè§†é¢‘ä¸­æ˜¯å¦å­˜åœ¨è·Œå€’è¡Œä¸º"
  }'

# æŸ¥çœ‹çŠ¶æ€
curl http://localhost:8080/api/llm/status

# å¥åº·æ£€æŸ¥
curl http://localhost:8080/api/llm/health
```

### Python ç¤ºä¾‹

```python
import requests

# è§†é¢‘æ¨ç†
response = requests.post('http://localhost:8080/api/llm/inference', json={
    'videoUrl': 'https://example.com/video.mp4',
    'customPrompt': 'åˆ†æè§†é¢‘ä¸­çš„è¡Œä¸ºé£é™©'
})

result = response.json()
if result['success']:
    print(f"æ¨ç†æˆåŠŸï¼Œè€—æ—¶: {result['inferenceTime']}ç§’")
    print(f"æ£€æµ‹åˆ°çš„åŠ¨ä½œ: {result['result']['action_analysis']['detected_action']}")
else:
    print(f"æ¨ç†å¤±è´¥: {result['error']}")
```

## æ—¥å¿—

æœåŠ¡æ—¥å¿—ä¿å­˜åœ¨ `logs/eldermind-llm.log`ï¼ŒåŒ…å«è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹å’Œé”™è¯¯ä¿¡æ¯ã€‚

## æ³¨æ„äº‹é¡¹

1. **API Key**: ç¡®ä¿é…ç½®äº†æœ‰æ•ˆçš„æ™ºè°±AI API Key
2. **è§†é¢‘URL**: åªæ”¯æŒå¯å…¬å¼€è®¿é—®çš„è§†é¢‘URLï¼Œä¸æ”¯æŒæœ¬åœ°æ–‡ä»¶è·¯å¾„
3. **è§†é¢‘æ ¼å¼**: æ”¯æŒå¸¸è§çš„è§†é¢‘æ ¼å¼ï¼ˆMP4ã€AVIç­‰ï¼‰
4. **ç½‘ç»œè®¿é—®**: ç¡®ä¿æœåŠ¡å™¨å’Œæ™ºè°±AIéƒ½èƒ½å¤Ÿè®¿é—®è§†é¢‘URL
5. **é™æµ**: æ³¨æ„APIè°ƒç”¨é¢‘ç‡é™åˆ¶
6. **å­˜å‚¨**: æ¨ç†ç»“æœä¼šä¿å­˜åˆ°æœ¬åœ° `llm_results` ç›®å½•

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **API Key é”™è¯¯**: æ£€æŸ¥æ™ºè°±AI API Keyæ˜¯å¦æ­£ç¡®é…ç½®
2. **è§†é¢‘æ— æ³•è®¿é—®**: ç¡®è®¤è§†é¢‘URLå¯ä»¥æ­£å¸¸è®¿é—®
3. **æ¨ç†è¶…æ—¶**: è°ƒæ•´ `timeout` é…ç½®æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥
4. **é™æµé”™è¯¯**: é™ä½è¯·æ±‚é¢‘ç‡æˆ–è°ƒæ•´é™æµé…ç½®

### æ—¥å¿—æŸ¥çœ‹

```bash
tail -f logs/eldermind-llm.log
```

## å¼€å‘

### æ„å»º

```bash
mvn clean package
```

### è¿è¡Œæµ‹è¯•

```bash
mvn test
```

### Docker éƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t eldermind-llm-server .

# è¿è¡Œå®¹å™¨
docker run -p 8080:8080 -e ZHIPU_API_KEY=your-api-key eldermind-llm-server
```
